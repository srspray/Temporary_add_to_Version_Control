---
title: "Practical Machine Learning Course Project"
author: "Sarah Spray"
date: "9/2/2021"
output:
  html_document:
    theme: "sandstone"
    toc: yes
    highlight: "zenburn"
    keep_md: TRUE
---



# Synopsis

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har.

The goal of your project is to predict the manner in which they did the exercise. This will be found in the "classe" variable in the training set. As a result, this report will describe how I built my model, how I used cross validation, what the expected out of sample error is, and why I made the choices I did. 

# Pre-Processing (Downloading the Data and Loading Packages for our Analysis) 

The Data for this project was downloaded from the course website and saved to a local computer. It was then loaded into R using the following code: 


```r
setwd("C:/Users/srspr/OneDrive/Desktop/Data Science/Practical Machine Learning")
TrainDataFileURL <- 
  "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
TrainDataFile <- "data/train.csv"
if (!file.exists('data')) {
    dir.create('data')
}
if (!file.exists(TrainDataFile)) {
    download.file(url = TrainDataFileURL, destfile = TrainDataFile)
}
Training <- read.csv(TrainDataFile, sep = ",", header = TRUE)
TestDataFileURL <- 
  "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
TestDataFile <- "data/test.csv"
if (!file.exists('data')) {
    dir.create('data')
}
if (!file.exists(TestDataFile)) {
    download.file(url = TestDataFileURL, destfile = TestDataFile)
}
Validation <- read.csv(TestDataFile, sep = ",", header = TRUE)
```

The following packages were loaded for our analysis.  I have also loaded the packages I will be using for parallel processing, and configured it so that I can utilize it when building my model.  


```r
library(caret)
library(lattice)
library(ggplot2)
library(AppliedPredictiveModeling)
library(randomForest)
library(plyr)
library(dplyr)
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) 
registerDoParallel(cluster)
```

# Cleaning the Data 

First we will start, by looking at the data and selecting the variables appropriate for our analysis:


```r
str(Training)
```

```
## 'data.frame':	19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : chr  "carlitos" "carlitos" "carlitos" "carlitos" ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : chr  "05/12/2011 11:23" "05/12/2011 11:23" "05/12/2011 11:23" "05/12/2011 11:23" ...
##  $ new_window              : chr  "no" "no" "no" "no" ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ kurtosis_roll_belt      : chr  "" "" "" "" ...
##  $ kurtosis_picth_belt     : chr  "" "" "" "" ...
##  $ kurtosis_yaw_belt       : chr  "" "" "" "" ...
##  $ skewness_roll_belt      : chr  "" "" "" "" ...
##  $ skewness_roll_belt.1    : chr  "" "" "" "" ...
##  $ skewness_yaw_belt       : chr  "" "" "" "" ...
##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_belt            : chr  "" "" "" "" ...
##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_belt            : chr  "" "" "" "" ...
##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : chr  "" "" "" "" ...
##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ kurtosis_roll_arm       : chr  "" "" "" "" ...
##  $ kurtosis_picth_arm      : chr  "" "" "" "" ...
##  $ kurtosis_yaw_arm        : chr  "" "" "" "" ...
##  $ skewness_roll_arm       : chr  "" "" "" "" ...
##  $ skewness_pitch_arm      : chr  "" "" "" "" ...
##  $ skewness_yaw_arm        : chr  "" "" "" "" ...
##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ kurtosis_roll_dumbbell  : chr  "" "" "" "" ...
##  $ kurtosis_picth_dumbbell : chr  "" "" "" "" ...
##  $ kurtosis_yaw_dumbbell   : chr  "" "" "" "" ...
##  $ skewness_roll_dumbbell  : chr  "" "" "" "" ...
##  $ skewness_pitch_dumbbell : chr  "" "" "" "" ...
##  $ skewness_yaw_dumbbell   : chr  "" "" "" "" ...
##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : chr  "" "" "" "" ...
##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : chr  "" "" "" "" ...
##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##   [list output truncated]
```

```r
str(Validation)
```

```
## 'data.frame':	20 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : chr  "pedro" "jeremy" "jeremy" "adelmo" ...
##  $ raw_timestamp_part_1    : int  1323095002 1322673067 1322673075 1322832789 1322489635 1322673149 1322673128 1322673076 1323084240 1322837822 ...
##  $ raw_timestamp_part_2    : int  868349 778725 342967 560311 814776 510661 766645 54671 916313 384285 ...
##  $ cvtd_timestamp          : chr  "05/12/2011 14:23" "30/11/2011 17:11" "30/11/2011 17:11" "02/12/2011 13:33" ...
##  $ new_window              : chr  "no" "no" "no" "no" ...
##  $ num_window              : int  74 431 439 194 235 504 485 440 323 664 ...
##  $ roll_belt               : num  123 1.02 0.87 125 1.35 -5.92 1.2 0.43 0.93 114 ...
##  $ pitch_belt              : num  27 4.87 1.82 -41.6 3.33 1.59 4.44 4.15 6.72 22.4 ...
##  $ yaw_belt                : num  -4.75 -88.9 -88.5 162 -88.6 -87.7 -87.3 -88.5 -93.7 -13.1 ...
##  $ total_accel_belt        : int  20 4 5 17 3 4 4 4 4 18 ...
##  $ kurtosis_roll_belt      : logi  NA NA NA NA NA NA ...
##  $ kurtosis_picth_belt     : logi  NA NA NA NA NA NA ...
##  $ kurtosis_yaw_belt       : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_belt      : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_belt.1    : logi  NA NA NA NA NA NA ...
##  $ skewness_yaw_belt       : logi  NA NA NA NA NA NA ...
##  $ max_roll_belt           : logi  NA NA NA NA NA NA ...
##  $ max_picth_belt          : logi  NA NA NA NA NA NA ...
##  $ max_yaw_belt            : logi  NA NA NA NA NA NA ...
##  $ min_roll_belt           : logi  NA NA NA NA NA NA ...
##  $ min_pitch_belt          : logi  NA NA NA NA NA NA ...
##  $ min_yaw_belt            : logi  NA NA NA NA NA NA ...
##  $ amplitude_roll_belt     : logi  NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : logi  NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : logi  NA NA NA NA NA NA ...
##  $ var_total_accel_belt    : logi  NA NA NA NA NA NA ...
##  $ avg_roll_belt           : logi  NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : logi  NA NA NA NA NA NA ...
##  $ var_roll_belt           : logi  NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : logi  NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : logi  NA NA NA NA NA NA ...
##  $ var_pitch_belt          : logi  NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : logi  NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : logi  NA NA NA NA NA NA ...
##  $ var_yaw_belt            : logi  NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  -0.5 -0.06 0.05 0.11 0.03 0.1 -0.06 -0.18 0.1 0.14 ...
##  $ gyros_belt_y            : num  -0.02 -0.02 0.02 0.11 0.02 0.05 0 -0.02 0 0.11 ...
##  $ gyros_belt_z            : num  -0.46 -0.07 0.03 -0.16 0 -0.13 0 -0.03 -0.02 -0.16 ...
##  $ accel_belt_x            : int  -38 -13 1 46 -8 -11 -14 -10 -15 -25 ...
##  $ accel_belt_y            : int  69 11 -1 45 4 -16 2 -2 1 63 ...
##  $ accel_belt_z            : int  -179 39 49 -156 27 38 35 42 32 -158 ...
##  $ magnet_belt_x           : int  -13 43 29 169 33 31 50 39 -6 10 ...
##  $ magnet_belt_y           : int  581 636 631 608 566 638 622 635 600 601 ...
##  $ magnet_belt_z           : int  -382 -309 -312 -304 -418 -291 -315 -305 -302 -330 ...
##  $ roll_arm                : num  40.7 0 0 -109 76.1 0 0 0 -137 -82.4 ...
##  $ pitch_arm               : num  -27.8 0 0 55 2.76 0 0 0 11.2 -63.8 ...
##  $ yaw_arm                 : num  178 0 0 -142 102 0 0 0 -167 -75.3 ...
##  $ total_accel_arm         : int  10 38 44 25 29 14 15 22 34 32 ...
##  $ var_accel_arm           : logi  NA NA NA NA NA NA ...
##  $ avg_roll_arm            : logi  NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : logi  NA NA NA NA NA NA ...
##  $ var_roll_arm            : logi  NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : logi  NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : logi  NA NA NA NA NA NA ...
##  $ var_pitch_arm           : logi  NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : logi  NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : logi  NA NA NA NA NA NA ...
##  $ var_yaw_arm             : logi  NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  -1.65 -1.17 2.1 0.22 -1.96 0.02 2.36 -3.71 0.03 0.26 ...
##  $ gyros_arm_y             : num  0.48 0.85 -1.36 -0.51 0.79 0.05 -1.01 1.85 -0.02 -0.5 ...
##  $ gyros_arm_z             : num  -0.18 -0.43 1.13 0.92 -0.54 -0.07 0.89 -0.69 -0.02 0.79 ...
##  $ accel_arm_x             : int  16 -290 -341 -238 -197 -26 99 -98 -287 -301 ...
##  $ accel_arm_y             : int  38 215 245 -57 200 130 79 175 111 -42 ...
##  $ accel_arm_z             : int  93 -90 -87 6 -30 -19 -67 -78 -122 -80 ...
##  $ magnet_arm_x            : int  -326 -325 -264 -173 -170 396 702 535 -367 -420 ...
##  $ magnet_arm_y            : int  385 447 474 257 275 176 15 215 335 294 ...
##  $ magnet_arm_z            : int  481 434 413 633 617 516 217 385 520 493 ...
##  $ kurtosis_roll_arm       : logi  NA NA NA NA NA NA ...
##  $ kurtosis_picth_arm      : logi  NA NA NA NA NA NA ...
##  $ kurtosis_yaw_arm        : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_arm       : logi  NA NA NA NA NA NA ...
##  $ skewness_pitch_arm      : logi  NA NA NA NA NA NA ...
##  $ skewness_yaw_arm        : logi  NA NA NA NA NA NA ...
##  $ max_roll_arm            : logi  NA NA NA NA NA NA ...
##  $ max_picth_arm           : logi  NA NA NA NA NA NA ...
##  $ max_yaw_arm             : logi  NA NA NA NA NA NA ...
##  $ min_roll_arm            : logi  NA NA NA NA NA NA ...
##  $ min_pitch_arm           : logi  NA NA NA NA NA NA ...
##  $ min_yaw_arm             : logi  NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : logi  NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : logi  NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : logi  NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  -17.7 54.5 57.1 43.1 -101.4 ...
##  $ pitch_dumbbell          : num  25 -53.7 -51.4 -30 -53.4 ...
##  $ yaw_dumbbell            : num  126.2 -75.5 -75.2 -103.3 -14.2 ...
##  $ kurtosis_roll_dumbbell  : logi  NA NA NA NA NA NA ...
##  $ kurtosis_picth_dumbbell : logi  NA NA NA NA NA NA ...
##  $ kurtosis_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_dumbbell  : logi  NA NA NA NA NA NA ...
##  $ skewness_pitch_dumbbell : logi  NA NA NA NA NA NA ...
##  $ skewness_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
##  $ max_roll_dumbbell       : logi  NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : logi  NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : logi  NA NA NA NA NA NA ...
##  $ min_roll_dumbbell       : logi  NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : logi  NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : logi  NA NA NA NA NA NA ...
##  $ amplitude_roll_dumbbell : logi  NA NA NA NA NA NA ...
##   [list output truncated]
```

```r
Training <- Training[,-(1:7)] # Based on our initial inspection of the data the first seven variables of our data (X, username, raw_timestamp_part_1, raw_timestamp_part_2,cvtd_timestamp, new_window, and num_window) will not be useful for our analysis and will therefore be dropped from our data set because they do not describe useful information for our outcome variable (i.e. "classe")
Validation <- Validation[,-(1:7)]
dim(Training)
```

```
## [1] 19622   153
```

```r
dim(Validation)
```

```
## [1]  20 153
```

After, looking at the variables in the training and validation sets. We still have over 153 variables.  In order to tidy our data set, we want to remove any variables that have a variance of zero. Therefore, I will remove all "near-zero-variance" predictors in the training set as well as in the validation set. In addition, I will also change to "classe" variable to a factor rather than a character.

Removing Near-Zero Variance Predictors


```r
Training1 <- nearZeroVar(Training)
Train <- Training[,-Training1]
Validation1 <- nearZeroVar(Validation)
Validation <- Validation[,-Validation1]
classe <- factor(Train$classe, levels = c("A", "B", "C", "D", "E"),
                 labels = c("A", "B", "C", "D", "E"))
dim(Train)
```

```
## [1] 19622    94
```

```r
dim(Validation)
```

```
## [1] 20 53
```

After removing the Near-Zero Variance Predictors from both our training and validation sets we have an unequal number of variables.  In order, to make sure we are using variables that have non-zero predictors we will only be using the variables that have non-zero predictors in our validation set to build our models.  As a result we will eliminate, the remaining variables that we have in our training set with the following code: 


```r
new <- intersect(colnames(Validation), colnames(Train))
new
```

```
##  [1] "roll_belt"            "pitch_belt"           "yaw_belt"            
##  [4] "total_accel_belt"     "gyros_belt_x"         "gyros_belt_y"        
##  [7] "gyros_belt_z"         "accel_belt_x"         "accel_belt_y"        
## [10] "accel_belt_z"         "magnet_belt_x"        "magnet_belt_y"       
## [13] "magnet_belt_z"        "roll_arm"             "pitch_arm"           
## [16] "yaw_arm"              "total_accel_arm"      "gyros_arm_x"         
## [19] "gyros_arm_y"          "gyros_arm_z"          "accel_arm_x"         
## [22] "accel_arm_y"          "accel_arm_z"          "magnet_arm_x"        
## [25] "magnet_arm_y"         "magnet_arm_z"         "roll_dumbbell"       
## [28] "pitch_dumbbell"       "yaw_dumbbell"         "total_accel_dumbbell"
## [31] "gyros_dumbbell_x"     "gyros_dumbbell_y"     "gyros_dumbbell_z"    
## [34] "accel_dumbbell_x"     "accel_dumbbell_y"     "accel_dumbbell_z"    
## [37] "magnet_dumbbell_x"    "magnet_dumbbell_y"    "magnet_dumbbell_z"   
## [40] "roll_forearm"         "pitch_forearm"        "yaw_forearm"         
## [43] "total_accel_forearm"  "gyros_forearm_x"      "gyros_forearm_y"     
## [46] "gyros_forearm_z"      "accel_forearm_x"      "accel_forearm_y"     
## [49] "accel_forearm_z"      "magnet_forearm_x"     "magnet_forearm_y"    
## [52] "magnet_forearm_z"
```

```r
Train <- subset(Train, select = new)
```

Next, I will remove all highly correlated predictors.  I will do this in order to address any issues of collinearity, and reduce the number of predictor variables. It's also important to note that when I found similar column names in our Training and Validation set the "classe" variable was dropped this could be due to the near-zero-variance with only 20 observations in our Validation set. Therefore, I will add it back in to the training set after removing highly correlated predictors. 


```r
TrainingCor <- Train %>% as.data.frame()
descrCor <- cor(TrainingCor)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .8 )
descrCor <- cor(TrainingCor)
summary(descrCor[upper.tri(descrCor)])
```

```
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## -0.992008 -0.110080  0.002092  0.001790  0.092552  0.980924
```

```r
highCorDescr <- findCorrelation(descrCor, cutoff = .8)
filteredDescr <- TrainingCor[,-highCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
```

```
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## -0.768688 -0.108470  0.009256  0.011198  0.110351  0.780565
```

```r
# add classe factor variable back into the training data 
Train <- cbind(filteredDescr, classe)
```

# Cross Validation 

Following the line of research on the given dataset, the paper posted at http://web.archive.org/web/20170519033209/http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf took a Random Forest approach.  I will also propose using a Random Forest approach.  In addition, I will use feature selection and set-up cross validation for my model using the function rfeControl in the caret package. I have selected 5-fold cross-validation.  I have also selected my model by selecting rfFuncs which implies the random forest algorithm.


```r
control <- rfeControl(functions = rfFuncs,
                      method = "cv",
                      number = 5,
                      allowParallel = TRUE)
```

Next, I will partition the dataset into a training and testing set. By placing, 60% of the data into my training set and 40% into my testing set. I have saved the independent variables in a separate dataset(i.e x, x_train) and the predictor variables in another dataset (y, y_train, etc.).


```r
x <- Train %>% select(-classe) %>% as.data.frame()
y <- Train$classe

set.seed(2021)
inTrain <- createDataPartition(y, p = 0.60, list = FALSE)[,1]

x_train <- x[inTrain, ]
x_test  <- x[-inTrain, ]

y_train <- y[inTrain]
y_test  <- y[-inTrain]
```

# Building my Model - Feature Selection 

In order to build my model, I put everything together in the rfe function, and set the sizes = c(1:10, 15, 20, 30, 35) so that the function tries to find all possible solutions with features 1, 2, 3...15, 20, or 35.


```r
result_rfe1 <- rfe(x = x_train, 
                   y = y_train, 
                   sizes = c(1:10, 15, 20, 30, 35),
                   rfeControl = control)
result_rfe1
```

```
## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (5 fold) 
## 
## Resampling performance over subset size:
## 
##  Variables Accuracy  Kappa AccuracySD   KappaSD Selected
##          1   0.5497 0.4262  0.0085545 0.0101681         
##          2   0.7785 0.7196  0.0111795 0.0141641         
##          3   0.8896 0.8603  0.0047502 0.0060878         
##          4   0.9307 0.9123  0.0045470 0.0057601         
##          5   0.9400 0.9241  0.0050539 0.0064225         
##          6   0.9510 0.9380  0.0055800 0.0070617         
##          7   0.9567 0.9452  0.0056093 0.0070869         
##          8   0.9631 0.9534  0.0073294 0.0092624         
##          9   0.9676 0.9591  0.0050941 0.0064470         
##         10   0.9740 0.9671  0.0028267 0.0035746         
##         15   0.9797 0.9743  0.0056215 0.0071116         
##         20   0.9863 0.9827  0.0023118 0.0029260         
##         30   0.9890 0.9861  0.0007602 0.0009616         
##         35   0.9896 0.9868  0.0010203 0.0012912        *
##         39   0.9896 0.9868  0.0009790 0.0012381         
## 
## The top 5 variables (out of 35):
##    yaw_belt, magnet_dumbbell_z, magnet_dumbbell_y, pitch_forearm, magnet_belt_y
```

```r
predictors(result_rfe1)
```

```
##  [1] "yaw_belt"             "magnet_dumbbell_z"    "magnet_dumbbell_y"   
##  [4] "pitch_forearm"        "magnet_belt_y"        "accel_dumbbell_y"    
##  [7] "gyros_belt_z"         "roll_arm"             "magnet_belt_z"       
## [10] "roll_forearm"         "magnet_forearm_z"     "roll_dumbbell"       
## [13] "magnet_dumbbell_x"    "yaw_dumbbell"         "yaw_arm"             
## [16] "magnet_belt_x"        "total_accel_dumbbell" "gyros_arm_y"         
## [19] "accel_forearm_x"      "accel_forearm_z"      "magnet_forearm_y"    
## [22] "magnet_arm_z"         "gyros_dumbbell_y"     "accel_arm_y"         
## [25] "pitch_arm"            "total_accel_belt"     "yaw_forearm"         
## [28] "magnet_arm_x"         "accel_forearm_y"      "accel_arm_z"         
## [31] "total_accel_arm"      "gyros_forearm_z"      "magnet_forearm_x"    
## [34] "total_accel_forearm"  "gyros_belt_x"
```

When running rfe it uses a recursive feature elimination algorithm.  After my initial run it recommended 35 features for the model. Ideally, we would have less features but that could be a limitation of our study or show the inconsistency of the data in predicting class(i.e. subject error with the exercise). Nonetheless, we can then take these features and put them in a final data frame and build our random forest model based on the techniques we learned in the Practical Machine Learning Course.


```r
X <- Train %>% select(yaw_belt, magnet_dumbbell_z, magnet_dumbbell_y,
                      pitch_forearm, magnet_belt_y, gyros_belt_z,
                      accel_dumbbell_y, magnet_belt_z, 
                      roll_arm, roll_forearm, magnet_forearm_z, roll_dumbbell,
                      magnet_dumbbell_x, yaw_dumbbell, magnet_belt_x, yaw_arm, 
                      total_accel_dumbbell, gyros_arm_y, accel_forearm_z, 
                      accel_forearm_x, magnet_forearm_y, magnet_arm_z,
                      gyros_dumbbell_y, pitch_arm, accel_arm_y, 
                      total_accel_belt, magnet_arm_x, 
                      yaw_forearm, accel_forearm_y, accel_arm_z,
                      total_accel_arm, gyros_forearm_z, total_accel_forearm,
                      magnet_forearm_x, gyros_belt_x, classe,)

# We will Partition our Data Again and Set-up Cross Validation before running our final model 
set.seed(2021)
inTrain <- createDataPartition(X$classe, p = 0.60, list = FALSE)
finaltraining <- X[ inTrain, ]
finaltesting  <- X[-inTrain, ]
fitControl <- trainControl(method='cv', number = 5,
                           allowParallel = TRUE)
```

Finally, we will build our model on our testing set after using feature selection.  This portion may seem a little redundant; however, based on what was taught in the Practical Machine Learning Course I felt like it was necessary to show the features of the caret project we learned with the train function.  Had I decided to use the model that was constructed in the rfe function in caret, I could have easily predicted the model on my testing set with the code: postResample(predict(result_rfe1, x_test), y_test).  Nonetheless, I have built a model with the most important features from rfe and used the techniques that were taught in the Practical Machine Learning Course to build my final model.   


```r
modelRF <- train(classe ~ ., data = finaltraining, trControl=fitControl, 
                 method = "rf")
```

# Prediction and Out of Sample Error (confusion matrix) 

After Building our model we will want to predict the outcome for the test data using the random forest model.   We will also want to assess the out of sample error. To do this we run the following code: 


```r
predictRF <- predict(modelRF, newdata = finaltesting)
confusionmatrix <- confusionMatrix(predictRF, finaltesting$classe)
confusionmatrix
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2222   16    0    0    0
##          B    5 1497   16    0    0
##          C    2    5 1347   21    1
##          D    0    0    5 1263    2
##          E    3    0    0    2 1439
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9901          
##                  95% CI : (0.9876, 0.9921)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9874          
##                                           
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9955   0.9862   0.9846   0.9821   0.9979
## Specificity            0.9971   0.9967   0.9955   0.9989   0.9992
## Pos Pred Value         0.9929   0.9862   0.9789   0.9945   0.9965
## Neg Pred Value         0.9982   0.9967   0.9968   0.9965   0.9995
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2832   0.1908   0.1717   0.1610   0.1834
## Detection Prevalence   0.2852   0.1935   0.1754   0.1619   0.1840
## Balanced Accuracy      0.9963   0.9914   0.9901   0.9905   0.9986
```

Our final model, had an accuracy of 0.9901. With our Out-of-Sample error shown in the confusion matrix.  To explain this a little further, our model incorrectly categorized the A classe (16 times), the B classe (21 times), the C classe (29 times), the D classe (7 times), and the E classe (5 times).  This would lead to 78 misclassifications out of 7846 observations or an out of sample error of 0.009 which makes sense because the accuracy of our model was 0.9901.  

Finally, I will not use the validation(and/or test) set that was downloaded and use that for the second portion of this project that utilizes this set and applies it to a prediction quiz. 
